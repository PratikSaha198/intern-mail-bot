[{"id": "kukA0LcAAAAJ", "url_picture": "https://scholar.google.com/citations?view_op=medium_photo&user=kukA0LcAAAAJ", "name": "Yoshua Bengio", "affiliation": "Professor of computer science, University of Montreal, Mila, IVADO, CIFAR", "email": "yoshua.bengio@umontreal.ca", "interests": ["Machine learning", "deep learning", "artificial intelligence"], "citedby": 311468, "homepage": "https://yoshuabengio.org/", "publications": [{"name": "Gradient-based learning applied to document recognition", "url": "https://ieeexplore.ieee.org/abstract/document/726791/", "description": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows\u00a0\u2026", "summary": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task."}, {"name": "Deep learning", "url": "https://www.nature.com/articles/nature14539", "description": "Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.", "summary": "Deep learning allows computational models composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio. Recurrent nets have shone light on sequential data such as text and speech."}, {"name": "Generative adversarial nets", "url": "http://papers.nips.cc/paper/5423-generative-adversarial-nets", "description": "We propose a new framework for estimating generative models via adversarial nets, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitatively evaluation of the generated samples.", "summary": "We propose a new framework for estimating generative models via adversarial nets. We simultaneously train two models: a generative model that captures the data distribution, and a discriminative model that estimates the probability that a sample came from the training data rather than g. The training procedure for g is to maximize the probability of d making a mistake."}, {"name": "Deep learning", "url": "https://books.google.co.in/books?hl=en&lr=&id=omivDQAAQBAJ&oi=fnd&pg=PR5&ots=MMV5fmtHNZ&sig=krRF_MarHKd2fpzGba6STw_UMDw&redir_esc=y", "description": "An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.\u201cWritten by three experts in the field, Deep Learning is the only comprehensive book on the subject.\u201d\u2014Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceX Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured\u00a0\u2026", "summary": "This book introduces a broad range of topics in deep learning. Deep learning is a form of machine learning that enables computers to learn from experience. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones. \"deep learning is the only comprehensive book on the subject,\" says elon musk."}, {"name": "Neural machine translation by jointly learning to align and translate", "url": "https://arxiv.org/abs/1409.0473", "description": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-) search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-) alignments found by the model agree well with our intuition.", "summary": "Neural machine translation is a recently proposed approach to machine translation. It aims at building a single neural network that can be jointly tuned to maximize the translation performance. In this paper, we propose to extend a model to automatically (soft-) search for parts of a source sentence that are relevant to predicting a target word. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system"}]}, {"id": "q82Ij2QAAAAJ", "url_picture": "https://scholar.google.com/citations?view_op=medium_photo&user=q82Ij2QAAAAJ", "name": "Yen-Da Chen (\u9673\u5f65\u9054)", "affiliation": "\u2026 of Computer Information and Network Engineering Lunghwa University of Science and", "email": null, "interests": ["Yen-Da Chen (\u9673\u5f65\u9054)"], "citedby": 268094, "homepage": "https://www.facebook.com/ydchen.lhu", "publications": [{"name": "Observation of a new particle in the search for the Standard Model Higgs boson with the ATLAS detector at the LHC", "url": "https://www.sciencedirect.com/science/article/pii/S037026931200857X", "description": "A search for the Standard Model Higgs boson in proton\u2013proton collisions with the ATLAS detector at the LHC is presented. The datasets used correspond to integrated luminosities of approximately 4.8 fb\u2212 1 collected at s= 7 TeV in 2011 and 5.8 fb\u2212 1 at s= 8 TeV in 2012. Individual searches in the channels H\u2192 Z Z (\u204e)\u2192 4 \u2113, H\u2192 \u03b3 \u03b3 and H\u2192 W W (\u204e)\u2192 e \u03bd \u03bc \u03bd in the 8 TeV data are combined with previously published results of searches for H\u2192 Z Z (\u204e), W W (\u204e), b b\u00af and \u03c4+ \u03c4\u2212 in the 7 TeV data and results from improved analyses of the H\u2192 Z Z (\u204e)\u2192 4 \u2113 and H\u2192 \u03b3 \u03b3 channels in the 7 TeV data. Clear evidence for the production of a neutral boson with a measured mass of 126.0\u00b10.4 (stat)\u00b10.4 (sys) GeV is presented. This observation, which has a significance of 5.9 standard deviations, corresponding to a background fluctuation probability of 1.7\u00d7 10\u2212 9, is compatible with the production and decay of the Standard Model\u00a0\u2026", "summary": "Clear evidence for the production of a neutral boson with a measured mass of 126.00.4 (stat)0.4 (sys) gev is presented. This observation, which has a significance of 5.9 standard deviations, corresponding to a background fluctuation probability of 1.7 10 9 is compatible with the production and decay of the standard model."}, {"name": "The ATLAS simulation infrastructure", "url": "https://link.springer.com/article/10.1140/epjc/s10052-010-1429-9", "description": " The simulation software for the ATLAS Experiment at the Large Hadron Collider is being used for large-scale production of events on the LHC Computing Grid. This simulation requires many components, from the generators that simulate particle collisions, through packages simulating the response of the various detectors and triggers. All of these components come together under the ATLAS simulation infrastructure. In this paper, that infrastructure is discussed, including that supporting the detector description, interfacing the event generation, and combining the GEANT4 simulation of the response of the individual detectors. Also described are the tools allowing the software validation, performance testing, and the validation of the simulated output against known physics processes.", "summary": "Simulation software for the atlas experiment at the large hadron collider is being used. This simulation requires many components, from generators that simulate collisions to packages simulating the response of the various detectors and triggers. All of these components come together under the atlas simulation infrastructure. In this paper, that infrastructure is discussed, including that supporting the detector description."}, {"name": "Heart disease and stroke statistics\u20142018 update: a report from the American Heart Association", "url": "https://www.ahajournals.org/doi/10.1161/cir.0000000000000558", "description": "Each year, the American Heart Association (AHA), in conjunction with the Centers for Disease Control and Prevention, the National Institutes of Health, and other government agencies, brings together in a single document the most up-to-date statistics related to heart disease, stroke, and the cardiovascular risk factors listed in the AHA\u2019s My Life Check-Life\u2019s Simple 7 (Figure 1), which include core health behaviors (smoking, physical activity, diet, and weight) and health factors (cholesterol, blood pressure [BP], and glucose control) that contribute to cardiovascular health. The Statistical Update represents a critical resource for the lay public, policy makers, media professionals, clinicians, healthcare administrators, researchers, health advocates, and others seeking the best available data on these factors and conditions. Cardiovascular disease (CVD) and stroke produce immense health and economic burdens in the\u00a0\u2026", "summary": "Each year, the american heart association brings together in a single document the most up-to-date statistics related to heart disease, stroke, and cardiovascular risk factors. The statistical update represents a critical resource for the lay public, policy makers, policy makers, clinicians, and others seeking the best available data on these factors and conditions. The statistical update represents a critical resource for policy makers, policy makers, media professionals, clinicians,... Health advocates "}, {"name": "GW170817: observation of gravitational waves from a binary neutron star inspiral", "url": "https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.119.161101", "description": "On August 17, 2017 at 12\u2236 41: 04 UTC the Advanced LIGO and Advanced Virgo gravitational-wave detectors made their first observation of a binary neutron star inspiral. The signal, GW170817, was detected with a combined signal-to-noise ratio of 32.4 and a false-alarm-rate estimate of less than one per 8.0\u00d7 10 4 years. We infer the component masses of the binary to be between 0.86 and 2.26 M\u2299, in agreement with masses of known neutron stars. Restricting the component spins to the range inferred in binary neutron stars, we find the component masses to be in the range 1.17\u20131.60 M\u2299, with the total mass of the system 2.7 4\u2212 0.01+ 0.04 M\u2299. The source was localized within a sky region of 28 deg 2 (90% probability) and had a luminosity distance of 4 0\u2212 14+ 8 Mpc, the closest and most precisely localized gravitational-wave signal yet. The association with the \u03b3-ray burst GRB 170817A, detected by Fermi-GBM\u00a0\u2026", "summary": "On august 17, 2017 the gravitational-wave detectors made their first observation of a binary neutron star inspiral. The signal, gw170817, was detected with a combined signal-to-noise ratio of 32.4. The source was localized within a sky region of 28 deg 2 (90% probability) and had a luminosity distance of 4 0 14+ 8 mpc."}, {"name": "Measurement of the Z/ \u03b3* boson transverse momentum distribution in pp collisions at  TeV with the ATLAS detector", "url": "https://link.springer.com/content/pdf/10.1007/JHEP09(2014)145.pdf", "description": "This paper describes a measurement of the Z/\u03b3* boson transverse momentum spectrum using ATLAS proton-proton collision data at a centre-of-mass energy of TeV at the LHC. The measurement is performed in the Z/\u03b3*\u2192 e+ e\u2212 and Z/\u03b3*\u2192 \u03bc+ \u03bc\u2212 channels, using data corresponding to an integrated luminosity of 4.7 fb\u2212 1. Normalized differential cross sections as a function of the Z/\u03b3* boson transverse momentum are measured for transverse momenta up to 800 GeV. The measurement is performed inclusively for Z/\u03b3* rapidities up to 2.4, as well as in three rapidity bins. The channel results are combined, compared to perturbative and resummed QCD calculations and used to constrain the parton shower parameters of Monte Carlo generators.", "summary": "The measurement is performed in the z/* e+ e and z/* +  channels. The channel results are combined, compared to perturbative and resummed qcd calculations. The channel results are used to constrain the parton shower parameters of monte carlo generators."}]}, {"id": "LyEq7qEAAAAJ", "url_picture": "https://scholar.google.com/citations?view_op=medium_photo&user=LyEq7qEAAAAJ", "name": "David S. Johnson", "affiliation": "Visiting Professor, Columbia University Computer Science Department", "email": null, "interests": ["Algorithms", "computer science", "optimization", "traveling salesman problem", "bin packing"], "citedby": 239885, "homepage": "http://davidsjohnson.net/", "publications": [{"name": "Dynamic source routing in ad hoc wireless networks", "url": "https://link.springer.com/chapter/10.1007/978-0-585-29603-6_5", "description": " An ad hoc network is a collection of wireless mobile hosts forming a temporary network without the aid of any established infrastructure or centralized administration. In such an environment, it may be necessary for one mobile host to enlist the aid of other hosts in forwarding a packet to its destination, due to the limited range of each mobile host\u2019s wireless transmissions. This paper presents a protocol for routing in ad hoc networks that uses dynamic source routing. The protocol adapts quickly to routing changes when host movement is frequent, yet requires little or no overhead during periods in which hosts move less frequently. Based on results from a packet-level simulation of mobile hosts operating in an ad hoc network, the protocol performs well over a variety of environmental conditions such as host density and movement rates. For all but the highest rates of host movement simulated, the overhead of the\u00a0\u2026", "summary": "This paper presents a protocol for routing in ad hoc networks that uses dynamic source routing. The protocol adapts quickly to routing changes when host movement is frequent, yet requires little or no overhead during periods in which hosts move less frequently. The protocol performs well over a variety of environmental conditions, such as host density and movement rates."}, {"name": "Learning together and alone: Cooperative, competitive, and individualistic learning", "url": "https://psycnet.apa.org/record/1986-98283-000", "description": "This book is about competition, cooperation, and individualistic effort, and gives you, the teacher, an easier, more productive, and more enjoyable approach to teaching by combining theories of social psychology and classroom practice.", "summary": "This book is about competition, cooperation, and individualistic effort. It gives you, the teacher, an easier, more productive, and more enjoyable approach to teaching. It combines theories of social psychology and classroom practice. The book is available in paperback or e-book form at amazon.com and october 1st, 2013."}, {"name": "Initial sequencing and comparative analysis of the mouse genome", "url": "https://profiles.wustl.edu/en/publications/initial-sequencing-and-comparative-analysis-of-the-mouse-genome", "description": "The sequence of the mouse genome is a key informational tool for understanding the contents of the human genome and a key experimental tool for biomedical research. Here, we report the results of an international collaboration to produce a high-quality draft sequence of the mouse genome. We also present an initial comparative analysis of the mouse and human genomes, describing some of the insights that can be gleaned from the two sequences. We discuss topics including the analysis of the evolutionary forces shaping the size, structure and sequence of the genomes; the conservation of large-scale synteny across most of the genomes; the much lower extent of sequence orthology covering less than half of the genomes; the proportions of the genomes under selection; the number of protein-coding genes; the expansion of gene families related to reproduction and immunity; the evolution of proteins; and the identification of intraspecies polymorphism.", "summary": "This paper reports the results of an international collaboration to produce a high-quality draft sequence of the mouse genome. It also presents an initial comparative analysis of the mouse and human genomes. The sequence of the mouse genome is a key informational tool for understanding the contents of the human genome and a key experimental tool for biomedical research."}, {"name": "A performance comparison of multi-hop wireless ad hoc network routing protocols", "url": "https://dl.acm.org/doi/abs/10.1145/288235.288256", "description": "An ad hoc networkis a collwtion of wirelessmobilenodes dynamically forminga temporarynetworkwithoutthe use of anyexistingnetworkirrfrastructureor centralizedadministration. Dueto the limitedtransmissionrange of~ vlrelessnenvorkinterfaces, multiplenetwork \u201chops\u201d maybe neededfor one node to exchangedata ivithanotheracrox the network. In recentyears, a ttiery of nelvroutingprotocols~ geted specificallyat thisenvironment havebeen developed. but little pcrfomrartwinformationon mch protocol and no ralistic performancecomparisonbehvwrrthem ISavailable.~ Is paper presentsthe results of a derailedpacket-levelsimulationcomparing fourmulti-hopwirelessad hoc networkroutingprotocolsthat covera range of designchoices: DSDV, TORA, DSR and AODV.\\Vehave extended the/~ r-2networksimulatorto accuratelymodelthe MACand physical-layer behaviorof the IEEE 802.1 I wirelessLANstandard, includinga realistic\u00a0\u2026", "summary": "An ad hoc networkis a collwtion of wirelessmobilenodes dynamically forminga temporarynetworkwithoutthe use of anyexistingnetworkirrfrastructure. Dueto the limitedtransmissionrange of vlrelessnenvorkinterfaces, multiplenetwork \u201chops\u201d maybe needed. In recentyears, a ttiery of nelvroutingproto"}, {"name": "Estimating the reproducibility of psychological science", "url": "https://science.sciencemag.org/content/349/6251/aac4716.abstract", "description": "INTRODUCTION Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. Scientific claims should not gain credence because of the status or authority of their originator but by the replicability of their supporting evidence. Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error.RATIONALE There is concern about the rate and predictors of reproducibility, but limited evidence. Potentially problematic practices include selective reporting, selective analysis, and insufficient specification of the conditions necessary or sufficient to obtain the results. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding and is the means of establishing reproducibility of a finding with new data. We conducted a large-scale, collaborative effort to obtain an\u00a0\u2026", "summary": "Even research of exemplary quality may have irreproducible empirical findings because of random or systematic error. There is concern about the rate and predictors of reproducibility, but limited evidence. Direct replication is the attempt to recreate the conditions believed sufficient for obtaining a previously observed finding with new data. A large-scale, collaborative effort was conducted to obtain an..."}]}, {"id": "yi6DR64AAAAJ", "url_picture": "https://scholar.google.com/citations?view_op=medium_photo&user=yi6DR64AAAAJ", "name": "William H. Press", "affiliation": "Professor of Computer Science and Integrative Biology, UT Austin", "email": null, "interests": ["Computational Biology", "Algorithms", "Astrophysics"], "citedby": 212408, "homepage": "http://www.nr.com/whp", "publications": [{"name": "Numerical recipes 3rd edition: The art of scientific computing", "url": "https://books.google.co.in/books?hl=en&lr=&id=gn_4mpdN9WkC&oi=fnd&pg=PR13&ots=Ufxc_cHftj&sig=SwuSqdQYIANRo8fGJyQban93dUU&redir_esc=y", "description": "Co-authored by four leading scientists from academia and industry, Numerical Recipes Third Edition starts with basic mathematics and computer science and proceeds to complete, working routines. Widely recognized as the most comprehensive, accessible and practical basis for scientific computing, this new edition incorporates more than 400 Numerical Recipes routines, many of them new or upgraded. The executable C++ code, now printed in color for easy reading, adopts an object-oriented style particularly suited to scientific applications. The whole book is presented in the informal, easy-to-read style that made earlier editions so popular. Please visit www. nr. com or www. cambridge. org/us/numericalrecipes for more details. More information concerning licenses is available at: www. nr. com/licenses New key features: 2 new chapters, 25 new sections, 25% longer than Second Edition Thorough upgrades throughout the text Over 100 completely new routines and upgrades of many more. New Classification and Inference chapter, including Gaussian mixture models, HMMs, hierarchical clustering, Support Vector Machines New Computational Geometry chapter covers KD trees, quad-and octrees, Delaunay triangulation, and algorithms for lines, polygons, triangles, and spheres New sections include interior point methods for linear programming, Monte Carlo Markov Chains, spectral and pseudospectral methods for PDEs, and many new statistical distributions An expanded treatment of ODEs with completely new routines Plus comprehensive coverage of linear algebra, interpolation, special functions, random numbers, nonlinear sets of\u00a0\u2026", "summary": "This new edition incorporates more than 400 routines, many of them new or upgraded. The executable code, now printed in color for easy reading, adopts an object-oriented style. The whole book is presented in the informal, easy-to-read style that made earlier editions so popular. Please visit www. Nr. Com or www. Cambridge. Org/us/numericalrecipes."}, {"name": "Formation of galaxies and clusters of galaxies by self-similar gravitational condensation", "url": "http://articles.adsabs.harvard.edu/full/1974ApJ...187..425P", "description": "FIG. 2.-Numerical experiments: Growth of the mean, 80th percentile and 30th percentile cluster with expansion factor. Experiment A appears consistent with the relation M~ R2 which is predicted by the linear perturbation theory. Experiment B does not", "summary": "Growth of the mean, 80th percentile and 30th percentile cluster with expansion factor. Experiment appears consistent with the relation. M r2 which is predicted by the linear. Perturbation theory. Experiment b does not appear to be consistent with. The relation m r2 which is predicted by the. Linear perturbation theory."}, {"name": "The cosmological constant", "url": "https://link.springer.com/article/10.12942/lrr-2001-1", "description": "Astronomy and physics bring different perspectives to the\" cosmological constant problem.\" Originally introduced by Einstein as a new term in his gravitational field equations [and later regretted by him as\" the biggest blunder of my life\"(quoted in Gamow 1970)], the cosmological constant,", "summary": "Cosmological constant introduced by einstein as a new term in his gravitational field equations. \"cosmological constant\" was later regretted by him as \"the biggest blunder of my life\" cosmological constant, cosmology and physics bring different perspectives to the\" cosmological constant problem\" cosmological constant is a constant in space and time."}, {"name": "Numerical recipes in Pascal: the art of scientific computing", "url": "https://books.google.co.in/books?hl=en&lr=&id=cyQ_pIMYPEUC&oi=fnd&pg=PR11&ots=i2iPHOLqW4&sig=mhcUACJmBeAc2Ql4ottOTdrllNU&redir_esc=y", "description": "Numerical Recipes: The Art of Scientific Computing was first published in 1986 and became an instant classic among scientists, engineers, and social scientists. In this book the original, time-tested programs have been completely reworked into a clear, consistent Pascal style. This represents a significant improvement to the immensely successful programs contained in the first edition, which were originally written in Fortran. The authors make extensive use of pointers, dynamic memory allocation, and other features utilized by this language. The explanatory text accompanying the programs replicates the lucid, and easy-to-read prose found in the original version, and incorporates corrections, improvements, and explanations of special Pascal features. The product of a unique collaboration among four leading scientists in academic research and industry, Numerical Recipes in Pascal fills a long-recognized need for a practical, comprehensive handbook of scientific computing in the Pascal language. The book is designed both for the Pascal programmer who wants exposure to the techniques of scientific computing, and for the working scientist, social scientist, and engineer. The scope of the book ranges from standard areas of numerical analysis (linear algebra, differential equations, roots) through subjects useful to signal processing (Fourier methods, filtering), data analysis (least squares, robust fitting, statistical functions), simulation (random deviates and Monte Carlo), and more. The lively, informal text combined with an underlying degree of mathematical sophistication makes the book useful to a wide range of readers, beginning at the\u00a0\u2026", "summary": "Numerical recipes in pascal fills a long-recognized need for a practical, comprehensive handbook of scientific computing in the pascal language. The scope of the book ranges from standard areas of numerical analysis (linear algebra, differential equations, roots) authors make extensive use of pointers, dynamic memory allocation, and other features utilized by this language."}, {"name": "Rotating black holes: locally nonrotating frames, energy extraction, and scalar synchrotron radiation", "url": "http://articles.adsabs.harvard.edu/full/1972ApJ...178..347B/0000347.000.html", "description": "\" tube.\" When a-\u00f7 M, the orbits at rms, rmb, and rPh all have the same circumference and coordinate radius, although-as the embedding diagram shows clearly-they are in fact distinct.", "summary": "When a- m, the orbits at rms, rmb, and rph all have the same circumference and coordinate radius, although-as the embedding diagram shows clearly-they are in fact distinct. When a- m, the orbits at rms and rmb all have the same circumference and radius, although-as the diagram shows-they are in fact distinct."}]}, {"id": "Kv9AbjMAAAAJ", "url_picture": "https://scholar.google.com/citations?view_op=medium_photo&user=Kv9AbjMAAAAJ", "name": "Jiawei Han", "affiliation": "Abel Bliss Professor of Computer Science, University of Illinois", "email": null, "interests": ["data mining", "database systems", "data warehousing", "information networks"], "citedby": 191708, "homepage": "http://www.cs.uiuc.edu/~hanj", "publications": [{"name": "Data mining: concepts and techniques", "url": "https://books.google.co.in/books?hl=en&lr=&id=pQws07tdpjoC&oi=fnd&pg=PP1&ots=tzMx0TiBY3&sig=7S9QcFuWhIbx507jsOvlX3g_23g&redir_esc=y", "description": "Data Mining: Concepts and Techniques provides the concepts and techniques in processing gathered data or information, which will be used in various applications. Specifically, it explains data mining and the tools used in discovering knowledge from the collected data. This book is referred as the knowledge discovery from data (KDD). It focuses on the feasibility, usefulness, effectiveness, and scalability of techniques of large data sets. After describing data mining, this edition explains the methods of knowing, preprocessing, processing, and warehousing data. It then presents information about data warehouses, online analytical processing (OLAP), and data cube technology. Then, the methods involved in mining frequent patterns, associations, and correlations for large data sets are described. The book details the methods for data classification and introduces the concepts and methods for data clustering. The remaining chapters discuss the outlier detection and the trends, applications, and research frontiers in data mining. This book is intended for Computer Science students, application developers, business professionals, and researchers who seek information on data mining. Presents dozens of algorithms and implementation examples, all in pseudo-code and suitable for use in real-world, large-scale data mining projects Addresses advanced topics such as mining object-relational databases, spatial databases, multimedia databases, time-series databases, text databases, the World Wide Web, and applications in several fields Provides a comprehensive, practical look at the concepts and techniques you need to get the most out of your data", "summary": "This book is referred as the knowledge discovery from data (kdd) it focuses on the feasibility, usefulness, effectiveness, and scalability of techniques of large data sets. This book is intended for computer science students, application developers, business professionals, and researchers who seek information on data mining. Data mining: concepts and techniques provides the concepts and techniques in processing gathered data or information."}, {"name": "Mining frequent patterns without candidate generation", "url": "https://dl.acm.org/doi/abs/10.1145/335191.335372", "description": "Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist prolific patterns and/or long patterns. In this study, we propose a novel frequent pattern tree (FP-tree) structure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth. Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a highly condensed, much smaller data structure, which avoids costly, repeated database scans, (2) our FP-tree-based mining\u00a0\u2026", "summary": "Frequent pattern tree is an extended prefix-tree structure for storing frequent patterns. A large database is compressed into a highly condensed, much smaller data structure. Our fp-tree-based mining method, fp-growth, mines the complete set of frequent patterns. The fp-tree-based mining method uses pattern fragment growth to find frequent patterns."}, {"name": "Data mining: an overview from a database perspective", "url": "https://ieeexplore.ieee.org/abstract/document/553155/", "description": "Mining information and knowledge from large databases has been recognized by many researchers as a key research topic in database systems and machine learning, and by many industrial companies as an important area with an opportunity of major revenues. Researchers in many different fields have shown great interest in data mining. Several emerging applications in information-providing services, such as data warehousing and online services over the Internet, also call for various data mining techniques to better understand user behavior, to improve the service provided and to increase business opportunities. In response to such a demand, this article provides a survey, from a database researcher's point of view, on the data mining techniques developed recently. A classification of the available data mining techniques is provided and a comparative study of such techniques is presented.", "summary": "This article provides a survey, from a database researcher's point of view, on the data mining techniques developed recently. A classification of the available data mining techniques is provided and a comparative study of such techniques is presented. Data mining is a key research topic in database systems and machine learning. Emerging applications in information-providing services also call for various data mining techniques."}, {"name": "Prefixspan: Mining sequential patterns efficiently by prefix-projected pattern growth", "url": "http://jayurbain.com/msoe/cs498-datamining/prefixspan_mining_sequential_patterns_by_prefix_projected_growth.pdf", "description": "Sequential pattern mining is an important data mining problem with broad applications. It is challenging since one may need to examine a combinatorially explosive number of possible subsequence patterns. Most of the previously developed sequential pattern mining methods follow the methodology of]\uff65, \uff67\uff66\uff69\uff68 \uff66 \uff68 which may substantially reduce the number of combinations to be examined. However,], \uff67\uff66\uff69\uff68 \uff66 \uff68 still encounters problems when a sequence database is large and/or when sequential patterns to be mined are numerous and/or long. In this paper, we propose a novel sequential pattern mining method, called PrefixSpan (ie, Prefix-projected Sequential pattern mining), which explores prefixprojection in sequential pattern mining. PrefixSpan mines the complete set of patterns but greatly reduces the efforts of candidate subsequence generation. Moreover, prefix-projection substantially reduces the size of projected databases and leads to efficient processing. Our performance study shows that PrefixSpan outperforms both the], \uff67\uff66 \uff68 \uff66 \uff68-based GSP algorithm and another recently proposed method, FreeSpan, in mining large sequence databases.", "summary": "We propose a novel sequential pattern mining method, called prefixspan. Prefix-projection substantially reduces the size of projected databases and leads to efficient processing. Performance study shows that prefixspan outperforms both the],     -based gsp algorithm and another recently proposed method, freespan."}, {"name": "Mining frequent patterns without candidate generation: A frequent-pattern tree approach", "url": "https://link.springer.com/article/10.1023/B:DAMI.0000005258.31418.83", "description": " Mining frequent patterns in transaction databases, time-series databases, and many other kinds of databases has been studied popularly in data mining research. Most of the previous studies adopt an Apriori-like candidate set generation-and-test approach. However, candidate set generation is still costly, especially when there exist a large number of patterns and/or long patterns. In this study, we propose a novel frequent-pattern tree (FP-tree) structure, which is an extended prefix-tree structure for storing compressed, crucial information about frequent patterns, and develop an efficient FP-tree-based mining method, FP-growth, for mining the complete set of frequent patterns by pattern fragment growth. Efficiency of mining is achieved with three techniques: (1) a large database is compressed into a condensed, smaller data structure, FP-tree which avoids costly, repeated database scans, (2) our FP\u00a0\u2026", "summary": "Frequent-pattern tree (fp-tree) is an extended prefix-tree structure for storing information about frequent patterns. A large database is compressed into a condensed, smaller data structure, fp-tree which avoids costly, repeated database scans. Our fp-growth method for mining the complete set of frequent patterns by pattern fragment growth."}]}]